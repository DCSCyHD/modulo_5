---
title: "Clase 1. Concepto de datos ordenados para la minería de texto"
output: html_notebook
---

```{r include=FALSE}
library(tidyverse)
library(tidytext)
```

La idea de "datos ordenados" o _tidy data_ es una forma de manejar de forma efectiva y eso aplica también para el caso de los datos textuales. Según [Hadley Wickham (2004)]() los datos "tidy" tiene tres características:

- Cada variable (o atributo) es una columna
- Cada unidad (u observación) es una fila
- Cada tipo de unidad observacional es una tabla

(Si en esta definición les resuena aquello que en las materias de Metodología de la Investigación se llamaba "estructura tripartita del dato" o lo que Juan Samaja llamaba "estructura cuatriparti
ta del dato" están bien encaminades).

En el contexto de minería de texto, los datos ordenados van a tener la siguente estrucutra: un **token** por fila. Un **token** es una unidad conceptual y/o analíticamente signifactivas con las que dividimos un documento. Un **token** puede ser una palabra (ese será el caso más frecuente en este curso) pero también, [n-gramas](https://es.wikipedia.org/wiki/N-grama), oraciones e incluso párrafos. De hecho, un primer paso en el preprocesamiento de texto es dividir el corpus en **tokens**.

Como puede verse esta estructura difiere de otras formas de almacenar el texto crudo

- Cadena: el texto puede, por supuesto, almacenarse como cadenas, es decir, vectores de caracteres, dentro de R y, a menudo, los datos de texto se leen primero en la memoria de esta forma.
- Corpus: estos tipos de objetos suelen contener cadenas sin procesar anotadas con metadatos y detalles adicionales.
- Matriz documento-término: esta es una matriz dispersa que describe una colección (es decir, un corpus) de documentos con una fila para cada documento y una columna para cada término. El valor de la matriz suele ser el recuento de palabras o tf-idf.

Como iremos viendo, va a ser muy fácil pasar del texto en formato tidy a otros formatos. Particularmente, vamos a estar yendo y viniendo para diferentes tareas. Así, tendremos que modelar en formato Matrix-documento-término, pero llevaremos esos resultados a formato tidy para generar visualizaciones que nos permitan interpretar este modelo.

## Primer ejemplo

Marx escribió en el famoso Prólogo a la Contribución a la Crítica de la Economía Política de 1859:


```{r}
marx <- c("El conjunto de estas relaciones de producción forma la estructura económica de la sociedad, la base real sobre la que se levanta la superestructura jurídica y política y a la que corresponden determinadas formas de conciencia social. El modo de producción de la vida material condiciona el proceso de la vida social política y espiritual en general. No es la conciencia del hombre la que determina su ser sino, por el contrario, el ser social es lo que determina su conciencia. Al llegar a una fase determinada de desarrollo las fuerzas productivas materiales de la sociedad entran en contradicción con las relaciones de producción existentes o, lo que no es más que la expresión jurídica de esto, con las relaciones de propiedad dentro de las cuales se han desenvuelto hasta allí. De formas de desarrollo de las fuerzas productivas, estas relaciones se convierten en trabas suyas, y se abre así una época de revolución social. Al cambiar la base económica se transforma, más o menos rápidamente, toda la inmensa superestructura erigida sobre ella.")

marx
```

¿Qué formato de los que vimos hasta aquí sería este?

Para poder analizarlo como datos tidy, primero tenemos que llevarlo a un dataframe.
```{r}
marx_df <- tibble(line = 1, text = marx)
marx_df
```
¿Qué significa que este marco de datos se ha impreso como un "tibble"? Un tibble es una clase moderna de marco de datos dentro de R, disponible en los paquetes dplyr y tibble, que tiene un método de impresión conveniente, no convierte cadenas en factores y no usa nombres de fila. Tibbles son ideales para usar con herramientas ordenadas.

Sin embargo, tenga en cuenta que este marco de datos que contiene texto aún no es compatible con un análisis de texto ordenado. No podemos filtrar las palabras ni contar las que ocurren con mayor frecuencia, ya que cada fila está formada por varias palabras combinadas. Necesitamos convertir esto para que tenga un token por documento por fila.

¿Cuántos documentos tenemos?

Dentro de nuestro marco de texto ordenado, necesitamos dividir el texto en tokens individuales (un proceso llamado tokenización) y transformarlo en una estructura de datos ordenada. Para hacer esto, usamos la función `unnest_tokens()` de tidytext.


```{r}
library(tidytext)

marx_df %>%
  unnest_tokens(word, text)
```

Usamos aquí dos argumentos básicos:

- el nombre de la columna de salida que se creará cuando el texto no esté anidado (palabra, en este caso), y luego 
- la columna de entrada de la que proviene el texto (texto, en este caso). 

Recordar que `text_df` arriba tiene una columna llamada `text` que contiene los datos de interés. A su vez `unnest_tokens()` realiza la tokenización por defecto usando palabras. Esto puede cambiarse sin problemas.

¿Qué formato tiene ahora?

A su vez, es importante observar que:

- Se conservan otras columnas, como el número de línea de donde proviene cada palabra.
- Se ha eliminado la puntuación.
- De forma predeterminada, `unnest_tokens()` convierte los tokens a minúsculas, lo que los hace más fáciles de comparar o combinar con otros conjuntos de datos. (Esto puede modificarse utilizando el argumento `to_lower = FALSE`)

Un diagrama del flujo de trabajo puede verse a continuación:

![](https://www.tidytextmining.com/images/tmwr_0101.png)


## Ordenando algunos textos de Marx y Engels

Vamos a trabajar con un dataset que el capo de [Diego Kosloski](https://sites.google.com/view/diego-kozlowski/home) escrapeó de la sección en español del [Marxist Internet Archive](https://www.marxists.org/espanol/). 

Cargamos los datos:
```{r}
marx_engels <- read_csv('../data/marx_engels.csv')
marx_engels
```

¿Qué estructura tiene este dataset?

Vamos a transformarlo en un formato tidy:

```{r}
marx_engels_tidy <- marx_engels %>%
        unnest_tokens(word, texto)
```


```{r}
marx_engels_tidy
```

## Eliminando stopwords
El siguiente paso es la eliminación de las llamadas stopwords. Se trata de palabras que o bien por su función sintáctica (pronombres, preposiciones, adverbios, etc.) o por su frecuencia (aparecen en gran frecuencia) no aportan información al texto.

En general, la forma estandar de lidiar con las stopwords es mediante su eliminación a través de una lista. Carguemos la lista con las stopwords, al mismo tiempo, vamos a eliminar los acentos de esta tabla.


```{r}
stop_words <- read_csv('https://raw.githubusercontent.com/Alir3z4/stop-words/master/spanish.txt', col_names=FALSE) %>%
        rename(word = X1) %>%
        mutate(word = stringi::stri_trans_general(word, "Latin-ASCII"))
```

Ahora sí, podemos removerlas usando la funcion `anti_join` 

```{r}
marx_engels_tidy <- marx_engels_tidy %>%
  anti_join(stop_words)
```

Fíjense cómo pasamos de aprimadamente 1.000.000 de palabras a 529.000 luego de eliminar las stop_words.
Ahora bien, ¿cuáles son las palabras más usadas por Marx y Engels?

```{r}
marx_engels_tidy %>%
        count(word, sort=TRUE)
```

Debido a que hemos estado usando herramientas ordenadas, nuestros recuentos de palabras se almacenan en un marco de datos ordenado. Esto nos permite canalizar esto directamente al paquete `ggplot2`, por ejemplo, para crear una visualización de las palabras más comunes:

```{r}
marx_engels_tidy %>%
        count(word, sort=TRUE) %>%
        filter(n > 600) %>%
        mutate(word = reorder(word, n)) %>%
        ggplot(aes(n, word)) +
                geom_col() +
                labs(y = NULL)

```

Podríamos evaluar ahora si Marx y Engels usan diferentes palabras en las cargas y notas y en sus libros. Para ello vamos a tener que procesar un poco el campo de `titulo`:


```{r}
marx_engels_tidy <- marx_engels_tidy %>%
        mutate(tipo = case_when(
                str_detect(titulo, 'Carta') ~ 'cartas',
                TRUE ~ tipo
        )) 
```

Utilizamos la función `str_detect` del paquete `stringr` para testear si la condición se cumple... en este caso si la palabra `Carta` aparece en las filas de `título`.

```{r}
freqs <- marx_engels_tidy %>%
        mutate(word = str_extract(word, "[a-z']+")) %>%
        group_by(tipo, word) %>%
        summarise(n = n()) %>%
        mutate(
                total = sum(n),
                prop = n/total*100) %>%
        select(tipo, word, prop) %>%
        pivot_wider(names_from = tipo, values_from = prop)
freqs
```

Y ahora podemos hacer un gráfico en el que comparamos la frecuencia de uso de las diferentes palabras en los libros y las notas: 

```{r}
freqs %>%
ggplot( aes(notas, libros)) +
  geom_jitter(alpha = 0.05, size = 2.5, width = 0.25, height = 0.25) +
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10() +
  scale_y_log10() +
  geom_abline(color = "red") +
  theme_minimal()
```

Las palabras que están cerca de la línea en estos gráficos tienen frecuencias similares en ambos conjuntos de textos, por ejemplo, tanto en los libros de Marx y Engels como en las aparecen con frecuencias simialres: burguesa, acción, campesinos, abolición, comuna, producción, clase. En cambio, en los libros parecen aparecer palabras como esencia, concepto, hegel, indidiuo, fenomenología, misterio. En las notas periodísitcas aparece notablemente palabras ligadas a la acción política: congreso, consejo, internacional, liga, estatutos, etc.


### Actividad
Repetir el ejercicio comparando las cartas con los libros

```{r}

```


